{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnVlXuDAcSWq"
   },
   "source": [
    "# **Libraries & settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cXimJlSIIE9J"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EzABZSVnTUDb",
    "outputId": "8dfe197f-45df-479f-8de3-852cc5033212"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "q871yxnzu0BN"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoeUmZqjRKil"
   },
   "source": [
    "# **Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VmBBK__3h5X"
   },
   "source": [
    "## **Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4fWu0FIhJMgV"
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, dropout_p=0.5):\n",
    "        super(Embedding, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.d_model)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        emb_input = self.dropout(self.embedding(input))\n",
    "\n",
    "        return emb_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sS35rpWLlXfX"
   },
   "source": [
    "## **Positional encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT6f8lUSwAAg"
   },
   "source": [
    "Thanks [ARUNMOHAN_003](https://www.kaggle.com/arunmohan003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RYphIqqouPxA"
   },
   "outputs": [],
   "source": [
    "class Positional_encoding(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(Positional_encoding, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        positional_encoding = torch.zeros(MAX_SEQ_LEN, self.d_model)\n",
    "\n",
    "        for position in range(MAX_SEQ_LEN):\n",
    "            for i in range(0, self.d_model, 2):\n",
    "                positional_encoding[position, i] = np.sin(\n",
    "                    position / (10000 ** ((2 * i)/self.d_model))\n",
    "                )\n",
    "                positional_encoding[position, i + 1] = np.cos(\n",
    "                    position / (10000 ** ((2 * (i + 1))/self.d_model))\n",
    "                )\n",
    "\n",
    "        positional_encoding = positional_encoding.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('positional_encoding', positional_encoding)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input + np.sqrt(self.d_model)\n",
    "\n",
    "        input_len = input.size(1)\n",
    "        input += torch.autograd.Variable(\n",
    "            self.positional_encoding[:,:input_len],\n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LT7t_Xz24Ad0"
   },
   "source": [
    "## **Multihead attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUatP0ZpiUsz"
   },
   "source": [
    "### **Scaled dot product attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpyKeGuk4JI5"
   },
   "source": [
    "Scaled dot product attention it is calculated according to the formula (see the article [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf))\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^{T}}{\\sqrt{d_k}}\\right)V,$$\n",
    "where $\\sqrt{d_k}$ is a \"queries and keys of dimension\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWSsU5KWLqnt"
   },
   "source": [
    "Here is the scaled dot product attention scheme from [original article](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsAS1H9Gs-ee"
   },
   "source": [
    "![Scaled Dot-Product Attention.svg](https://svgshare.com/i/tnP.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DGes1IaeiT_T"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attn(Q, K, V, mask=None):\n",
    "    d_k = K.size(-1)\n",
    "\n",
    "    attn_weights = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        attn_weights = attn_weights.masked_fill(mask, -1e13)\n",
    "\n",
    "    attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "    \n",
    "    attention_applied = torch.matmul(attn_weights, V)\n",
    "\n",
    "    return attention_applied, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBshOaQRidQx"
   },
   "source": [
    "### **Multihead attention**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtW8W1pML2o8"
   },
   "source": [
    "Here is the multihead attention scheme from [original article](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgEUHzo7vBo-"
   },
   "source": [
    "![Multi-Head Attention.svg](https://svgshare.com/i/toS.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qPQfgI6aihLE"
   },
   "outputs": [],
   "source": [
    "class Multihead_attention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(Multihead_attention, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = self.d_model // self.n_heads\n",
    "\n",
    "        assert (\n",
    "            self.n_heads * self.d_head == self.d_model\n",
    "        ), \"d_head * n_heads must be equal to d_model!\"\n",
    "\n",
    "        self.W_Q = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.W_K = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.W_V = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "\n",
    "        self.fc = nn.Linear(self.n_heads * self.d_head, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        batch_size = K.size(0)\n",
    "        K_len = K.size(1)\n",
    "        Q_len = Q.size(1)\n",
    "        \n",
    "        Q = self.W_Q(Q)\n",
    "        K = self.W_K(K)\n",
    "        V = self.W_V(V)\n",
    "\n",
    "        Q = Q.reshape(batch_size, Q_len, self.n_heads, self.d_head)\n",
    "        K = K.reshape(batch_size, K_len, self.n_heads, self.d_head)\n",
    "        V = V.reshape(batch_size, K_len, self.n_heads, self.d_head)\n",
    "\n",
    "        Q = Q.permute(0, 2, 1, 3)\n",
    "        K = K.permute(0, 2, 1, 3)\n",
    "        V = V.permute(0, 2, 1, 3)\n",
    "\n",
    "        attention, attn_weights = scaled_dot_product_attn(Q, K, V, mask)\n",
    "        attention = attention.permute(0, 2, 1, 3)\n",
    "        attention = attention.reshape(batch_size, Q_len, self.d_model)\n",
    "\n",
    "        attention = self.fc(attention)\n",
    "\n",
    "        return attention, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLRUEPUh594c"
   },
   "source": [
    "## **Encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHG-K2_uPORF"
   },
   "source": [
    "### **Encoder block**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI7n_nmwCAG6"
   },
   "source": [
    "Here is the block of encoder scheme from [original article](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr0uI9R4xalM"
   },
   "source": [
    "![Encoder block.svg](https://svgshare.com/i/toE.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HMoGYiRU65yv"
   },
   "outputs": [],
   "source": [
    "class Encoder_block(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ffn, dropout_p=0.5):\n",
    "        super(Encoder_block, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ffn = d_ffn\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.attention = Multihead_attention(self.d_model, self.n_heads)\n",
    "        \n",
    "        self.FFN = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.d_ffn),\n",
    "            nn.Dropout(self.dropout_p),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.d_ffn, self.d_model)\n",
    "        )\n",
    "\n",
    "        self.layer_norm_1 = nn.LayerNorm(self.d_model)\n",
    "        self.layer_norm_2 = nn.LayerNorm(self.d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "    def forward(self, input, mask=None):\n",
    "        attention_out, attention_weights = self.attention(input, input, input, mask)\n",
    "        attention_out = input + self.dropout(attention_out)\n",
    "        attention_out = self.layer_norm_1(attention_out)\n",
    "\n",
    "        ffn_out = self.FFN(attention_out)\n",
    "        ffn_out = attention_out + self.dropout(ffn_out)\n",
    "        out = self.layer_norm_2(ffn_out)\n",
    "        \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqejdbdEy9vB"
   },
   "source": [
    "### **Full encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt28tKVYzGhQ"
   },
   "source": [
    "Here is the full encoder scheme from [original article](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc-M5YjUxXLG"
   },
   "source": [
    "![Encoder.svg](https://svgshare.com/i/tob.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1bWoRWFmKfgm"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, model_params_dict, data_params_dict):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = model_params_dict[\"d_model\"]\n",
    "        self.n_heads = model_params_dict[\"n_heads\"]\n",
    "        self.d_ffn = model_params_dict[\"d_ffn\"]\n",
    "        self.n_layers = model_params_dict[\"n_layers\"]\n",
    "        self.src_vocab_size = data_params_dict[\"src_vocab_size\"]\n",
    "        self.dropout_p = model_params_dict[\"dropout_p\"]\n",
    "\n",
    "        self.src_embedding = Embedding(self.src_vocab_size, self.d_model)\n",
    "        self.positional_encoding = Positional_encoding(self.d_model)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            Encoder_block(self.d_model,\n",
    "                          self.n_heads,\n",
    "                          self.d_ffn,\n",
    "                          self.dropout_p)\n",
    "            for _ in range(self.n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, src, mask=None):\n",
    "        encoder_input = self.src_embedding(src)\n",
    "        encoder_input = self.positional_encoding(encoder_input)\n",
    "        \n",
    "        attention_weights = None\n",
    "\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoder_input, attention_weights = encoder_layer(\n",
    "                encoder_input,\n",
    "                mask\n",
    "            )\n",
    "\n",
    "        return encoder_input, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0wvcnjATrH2"
   },
   "source": [
    "## **Decoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVAturMnY8-f"
   },
   "source": [
    "### **Decoder block**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMjq8A8axeqX"
   },
   "source": [
    "Here is the block of decoder scheme from [original article](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5rg4utIzYJ0"
   },
   "source": [
    "![Decoder block.svg](https://svgshare.com/i/tni.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1KuNHobh9EfT"
   },
   "outputs": [],
   "source": [
    "class Decoder_block(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ffn, dropout_p):\n",
    "        super(Decoder_block, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_ffn = d_ffn\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        self.attention_1 = Multihead_attention(self.d_model, self.n_heads)\n",
    "        self.attention_2 = Multihead_attention(self.d_model, self.n_heads)\n",
    "        \n",
    "        self.FFN = nn.Sequential(\n",
    "            nn.Linear(self.d_model, self.d_ffn),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.d_ffn, self.d_model)\n",
    "        )\n",
    "\n",
    "        self.layer_norm_1 = nn.LayerNorm(self.d_model)\n",
    "        self.layer_norm_2 = nn.LayerNorm(self.d_model)\n",
    "        self.layer_norm_3 = nn.LayerNorm(self.d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, decoder_inputs, target_mask, src_mask=None):\n",
    "        attention_out_1, _ = self.attention_1(\n",
    "            decoder_inputs,\n",
    "            decoder_inputs,\n",
    "            decoder_inputs,\n",
    "            target_mask\n",
    "        )\n",
    "        attention_out_1 = self.dropout(attention_out_1) + decoder_inputs \n",
    "        attention_out_1 = self.layer_norm_1(attention_out_1)\n",
    "\n",
    "        attention_out_2, attention_weights_2 = self.attention_2(\n",
    "            attention_out_1,\n",
    "            encoder_outputs,\n",
    "            encoder_outputs,\n",
    "            src_mask\n",
    "        )\n",
    "        attention_out_2 = self.dropout(attention_out_2) + attention_out_1 \n",
    "        attention_out_2 = self.layer_norm_1(attention_out_2)\n",
    "\n",
    "        ffn_out = self.FFN(attention_out_2)\n",
    "        ffn_out = self.dropout(ffn_out) + attention_out_2\n",
    "        out = self.layer_norm_3(ffn_out)\n",
    "        \n",
    "        return out, attention_weights_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AASbwKRRZB37"
   },
   "source": [
    "### **Full decoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lb74JjKcxjqS"
   },
   "source": [
    "Here is the full decoder scheme from [original article](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0mv-CCXxUZb"
   },
   "source": [
    "![Decoder.svg](https://svgshare.com/i/tnu.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fKLIPgSh-SHx"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, model_params_dict, data_params_dict):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = model_params_dict[\"d_model\"]\n",
    "        self.n_heads = model_params_dict[\"n_heads\"]\n",
    "        self.d_ffn = model_params_dict[\"d_ffn\"]\n",
    "        self.n_layers = model_params_dict[\"n_layers\"]\n",
    "        self.target_vocab_size = data_params_dict[\"target_vocab_size\"]\n",
    "        self.dropout_p = model_params_dict[\"dropout_p\"]\n",
    "\n",
    "        self.target_embedding = Embedding(self.target_vocab_size, self.d_model)\n",
    "        self.positional_encoding = Positional_encoding(self.d_model)\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            Decoder_block(self.d_model,\n",
    "                          self.n_heads,\n",
    "                          self.d_ffn,\n",
    "                          self.dropout_p)\n",
    "            for _ in range(self.n_layers)\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(self.d_model, self.target_vocab_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, target, target_mask, src_mask):\n",
    "        decoder_input = self.target_embedding(target)\n",
    "        decoder_input = self.positional_encoding(decoder_input)\n",
    "        attention_weights = None\n",
    "\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            decoder_input, attention_weights = decoder_layer(\n",
    "                encoder_outputs,\n",
    "                decoder_input,\n",
    "                target_mask,\n",
    "                src_mask\n",
    "            )\n",
    "\n",
    "        out = self.fc(decoder_input)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqKdRQ-JyycB"
   },
   "source": [
    "## **Transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byNB9gyyzxf3"
   },
   "source": [
    "Now let's put the encoder and decoder together. We will get this scheme:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CQ_gsXezyIr"
   },
   "source": [
    "![Transformer.svg](https://svgshare.com/i/to4.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vE528RdD-sIz"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_params_dict, data_params_dict):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(model_params_dict, data_params_dict).to(device)\n",
    "        self.decoder = Decoder(model_params_dict, data_params_dict).to(device)\n",
    "\n",
    "    def forward(self, src_batch, target_batch):\n",
    "        batch_size = target_batch.size(0)\n",
    "        target_len = target_batch.size(1)\n",
    "\n",
    "        src_padding_mask = (src_batch != 0)[:, None, None, :].to(device)\n",
    "        target_padding_mask = (target_batch != 0)[:, None, None, :].to(device)\n",
    "\n",
    "        look_ahead_mask = torch.tril(\n",
    "            torch.ones((target_len, target_len))\n",
    "        ).expand(batch_size, 1, target_len, target_len).to(device)\n",
    "        \n",
    "        target_mask = torch.minimum(\n",
    "            target_padding_mask, look_ahead_mask\n",
    "        ).to(device)\n",
    "\n",
    "        encoder_out, _ = self.encoder(src_batch, src_padding_mask)\n",
    "\n",
    "        decoder_out, attention_weights = self.decoder(encoder_out,\n",
    "                                                      target_batch,\n",
    "                                                      target_mask,\n",
    "                                                      src_padding_mask)\n",
    "\n",
    "        return decoder_out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ltCZ7b7eT4Rr"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.xavier_uniform_(param.data.unsqueeze_(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBDgq804bbfg"
   },
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YPWnQ8IhMkqH"
   },
   "outputs": [],
   "source": [
    "model_params_dict = {\n",
    "    \"d_model\": 512,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 6,\n",
    "    \"d_ffn\": 2048,\n",
    "    \"dropout_p\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Kg3UK1gfMwoE"
   },
   "outputs": [],
   "source": [
    "data_params_dict = {\n",
    "    \"src_vocab_size\": 10,\n",
    "    \"target_vocab_size\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xED29HFgM9z6",
    "outputId": "4e2c58ef-de4d-4107-a683-dc3b8029cf51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (src_embedding): Embedding(\n",
       "      (embedding): Embedding(10, 512)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (positional_encoding): Positional_encoding()\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0-5): 6 x Encoder_block(\n",
       "        (attention): Multihead_attention(\n",
       "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (FFN): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): Dropout(p=0.1, inplace=False)\n",
       "          (2): ReLU()\n",
       "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (target_embedding): Embedding(\n",
       "      (embedding): Embedding(10, 512)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (positional_encoding): Positional_encoding()\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0-5): 6 x Decoder_block(\n",
       "        (attention_1): Multihead_attention(\n",
       "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (attention_2): Multihead_attention(\n",
       "          (W_Q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (W_K): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (W_V): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (FFN): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = Transformer(model_params_dict,\n",
    "                          data_params_dict).to(device)\n",
    "\n",
    "transformer.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-E4jPHFNIib",
    "outputId": "b18dbcdc-a2da-4ac5-aabb-920d7ddf0d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters count: 44126218\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in transformer.parameters() if p.requires_grad)\n",
    "print(\"parameters count:\", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gCx522ZSLt0"
   },
   "source": [
    "# **Toy example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "S6ykRzyoOXvp"
   },
   "outputs": [],
   "source": [
    "def make_decoder_inputs_targets(target_batch):\n",
    "    decoder_inputs = [sentence[:-1] for sentence in target_batch]\n",
    "    decoder_targets = [sentence[1:] for sentence in target_batch]\n",
    "\n",
    "    return decoder_inputs, decoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2qpqV8Sh5onY"
   },
   "outputs": [],
   "source": [
    "src_batch = [\n",
    "    torch.Tensor([1, 3, 4, 5, 6, 7, 2]),\n",
    "    torch.Tensor([1, 3, 4, 5, 7, 2])\n",
    "]\n",
    "\n",
    "target_batch = [\n",
    "    torch.Tensor([1, 3, 4, 5, 9, 6, 7, 2]),\n",
    "    torch.Tensor([1, 3, 4, 5, 2])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tUJpUdvK5pLG"
   },
   "outputs": [],
   "source": [
    "decoder_input, decoder_target = make_decoder_inputs_targets(target_batch)\n",
    "\n",
    "src_batch = pad_sequence(\n",
    "    src_batch, batch_first=True\n",
    ").type(\"torch.LongTensor\").to(device)\n",
    "decoder_input = pad_sequence(\n",
    "    decoder_input, batch_first=True\n",
    ").type(\"torch.LongTensor\").to(device)\n",
    "decoder_target = pad_sequence(\n",
    "    decoder_target, batch_first=True\n",
    ").type(\"torch.LongTensor\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghYsmLhUOZdv",
    "outputId": "6e050620-d2dd-44d2-d7dd-0346bf81f432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out size: torch.Size([2, 7, 10])\n",
      "out:\n",
      "tensor([[[-0.0038,  0.4486, -0.4517,  0.3078, -0.2433, -0.6049,  0.6106,\n",
      "           0.4409, -0.6878, -0.7472],\n",
      "         [-0.0091,  0.4403, -0.4499,  0.3200, -0.2299, -0.5959,  0.6084,\n",
      "           0.4386, -0.6753, -0.7451],\n",
      "         [-0.0154,  0.4476, -0.4459,  0.3112, -0.2317, -0.6035,  0.6089,\n",
      "           0.4447, -0.6738, -0.7398],\n",
      "         [-0.0195,  0.4444, -0.4598,  0.3093, -0.2298, -0.6069,  0.5983,\n",
      "           0.4452, -0.6846, -0.7374],\n",
      "         [-0.0080,  0.4459, -0.4456,  0.3164, -0.2365, -0.6076,  0.6132,\n",
      "           0.4409, -0.6781, -0.7452],\n",
      "         [-0.0073,  0.4462, -0.4583,  0.3243, -0.2301, -0.6107,  0.6029,\n",
      "           0.4407, -0.6841, -0.7405],\n",
      "         [-0.0062,  0.4549, -0.4452,  0.3204, -0.2380, -0.5979,  0.5991,\n",
      "           0.4343, -0.6890, -0.7381]],\n",
      "\n",
      "        [[-0.0183,  0.4576, -0.4430,  0.3170, -0.2403, -0.6013,  0.6040,\n",
      "           0.4463, -0.6906, -0.7506],\n",
      "         [-0.0067,  0.4523, -0.4448,  0.3177, -0.2392, -0.6063,  0.6067,\n",
      "           0.4446, -0.6844, -0.7408],\n",
      "         [-0.0035,  0.4466, -0.4467,  0.3094, -0.2348, -0.6161,  0.6099,\n",
      "           0.4398, -0.6857, -0.7424],\n",
      "         [-0.0067,  0.4563, -0.4494,  0.3173, -0.2331, -0.6082,  0.6123,\n",
      "           0.4368, -0.6756, -0.7442],\n",
      "         [-0.0097,  0.4443, -0.4495,  0.3125, -0.2270, -0.6002,  0.6005,\n",
      "           0.4442, -0.6810, -0.7556],\n",
      "         [-0.0126,  0.4413, -0.4411,  0.3240, -0.2416, -0.6069,  0.6201,\n",
      "           0.4334, -0.6827, -0.7414],\n",
      "         [-0.0109,  0.4418, -0.4515,  0.3199, -0.2268, -0.6087,  0.6147,\n",
      "           0.4493, -0.6760, -0.7397]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "attn_weights size: torch.Size([2, 8, 7, 7])\n",
      "attn_weights:\n",
      "tensor([[[[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429],\n",
      "          [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out, attn_weights = transformer(src_batch, decoder_input)\n",
    "print(f\"out size: {out.size()}\")\n",
    "print(f\"out:\\n{out}\\n\")\n",
    "print(f\"attn_weights size: {attn_weights.size()}\")\n",
    "print(f\"attn_weights:\\n{attn_weights}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
